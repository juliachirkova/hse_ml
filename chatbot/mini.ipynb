{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
      "\u001b[K     |████████████████████████████████| 567 kB 967 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /Users/julia/Library/Python/3.9/lib/python/site-packages (from openai) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting idna>=2.8\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 9.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /Users/julia/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 9.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: sniffio, idna, h11, certifi, pydantic-core, httpcore, anyio, annotated-types, tqdm, pydantic, jiter, httpx, distro, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.8.0 certifi-2025.1.31 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jiter-0.9.0 openai-1.66.3 pydantic-2.10.6 pydantic-core-2.27.2 sniffio-1.3.1 tqdm-4.67.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting inputimeout\n",
      "  Downloading inputimeout-1.0.4-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: inputimeout\n",
      "Successfully installed inputimeout-1.0.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install inputimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_api import mini_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_msg(role, content):\n",
    "   \n",
    "    return {\"role\": role, \"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hr_interview():\n",
    "    \"\"\"\n",
    "    Простой HR-чат-бот, который:\n",
    "    1. Приветствует кандидата.\n",
    "    2. Запоминает важную информацию (опыт, навыки, мотивацию и др.).\n",
    "    3. В конце по команде 'finish' формирует итоговую оценку кандидата.\n",
    "    \"\"\"\n",
    "\n",
    "    # Важная часть: сообщение от \"system\" задаёт роль бота.\n",
    "    system_message = create_msg(\n",
    "        \"system\",\n",
    "        (\n",
    "            \"Ты выступаешь в роли HR-бота в компании, которая ищет ML-разработчика. \"\n",
    "            \"Твоя задача – проводить первичное интервью и тщательно выяснять детали, важные для данной вакансии. \"\n",
    "            \"Основные требования к кандидату: 1) Сильные навыки машинного обучения и практический опыт (разработка моделей, работа с PyTorch или TensorFlow и т.д.) \"\n",
    "            \"2) Хорошее знание Python и основных библиотек (numpy, pandas, scikit-learn и др.) \"\n",
    "            \"3) Опыт работы с большими данными и/или облачными платформами (AWS, GCP, Azure) \"\n",
    "            \"4) Понимание процесса разработки (CI/CD, контейнеризация, git) \"\n",
    "            \"5) Умение разбираться в бизнес-требованиях и адаптировать ML-решения под них. \"\n",
    "            \"Ред-флаги (если обнаружим – не нанимаем): Явно завышенные или противоречивые сведения об опыте, нежелание учиться, конфликты с предыдущими работодателями, отсутствие понимания базовых принципов ML и математики. \"\n",
    "            \"Твои задачи: 1) Узнавать, какой у кандидата реальный опыт, какие проекты он реализовывал и какие навыки планирует развивать \"\n",
    "            \"2) Спрашивать о самых сложных технических проблемах, которые кандидат решал \"\n",
    "            \"3) Выяснять уровень владения ML-инструментами и умение решать реальные бизнес-задачи \"\n",
    "            \"4) Проверять, как кандидат подходит к обучению и повышению квалификации \"\n",
    "            \"5) Оценивать мягкие навыки (командная работа, коммуникации). \"\n",
    "            \"Когда заканчиваем диалог по команде 'finish' или подобному сигналу, сформулируй краткое резюме кандидата, выяви сильные и слабые стороны и сделай вывод о целесообразности найма, указав, если есть настораживающие моменты.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Изначально в истории будет только системное сообщение\n",
    "    history = [system_message]\n",
    "\n",
    "    print(\"Добро пожаловать на первичное интервью! (для выхода напишите 'exit', а для получения результата напишите 'finish')\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Кандидат: \").strip()\n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        # Выход из чата\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"HR-бот: Завершаем интервью. Удачи!\")\n",
    "            break\n",
    "\n",
    "        # Если пользователь хочет закончить и получить оценку\n",
    "        if user_input.lower() == \"finish\":\n",
    "            # Мы добавляем в историю специальное сообщение, чтобы бот сделал итог\n",
    "            finish_prompt = (\n",
    "                \"Сформируй резюме и итоговую оценку кандидата по следующим пунктам:\\n\"\n",
    "                \"1. Опыт работы и навыки\\n\"\n",
    "                \"2. Образование и достижения\\n\"\n",
    "                \"3. Мотивация и пожелания\\n\"\n",
    "                \"Затем оцени кандидата по шкале от 1 до 10 и предложи рекомендации для нанимающей компании.\"\n",
    "            )\n",
    "            history.append(create_msg(\"user\", finish_prompt))\n",
    "\n",
    "            ai_msg, cost = mini_chat(messages=history)\n",
    "            print(f\"HR-бот (итоговая оценка): {ai_msg}\")\n",
    "            print(f\"Цена последнего запроса: {cost}\")\n",
    "            print(\"\\nИнтервью завершено.\")\n",
    "            break\n",
    "\n",
    "        # Иначе продолжаем диалог\n",
    "        history.append(create_msg(\"user\", user_input))\n",
    "\n",
    "        try:\n",
    "            ai_msg, cost = mini_chat(messages=history)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обращении к модели: {e}\")\n",
    "            break\n",
    "\n",
    "        # Вывод ответа\n",
    "        print(f\"HR-бот: {ai_msg}\")\n",
    "        print(f\"Цена запроса: {cost}\\n\")\n",
    "\n",
    "        # Добавляем ответ бота в историю\n",
    "        history.append(create_msg(\"assistant\", ai_msg))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добро пожаловать на первичное интервью! (для выхода напишите 'exit', а для получения результата напишите 'finish')\n",
      "\n",
      "HR-бот (итоговая оценка): Конечно! Пожалуйста, предоставьте информацию о кандидате, чтобы я мог сформулировать резюме и итоговую оценку.\n",
      "Цена последнего запроса: 0.03\n",
      "\n",
      "Интервью завершено.\n"
     ]
    }
   ],
   "source": [
    "history = run_hr_interview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"Ты выступаешь в роли HR-бота в компании, которая ищет ML-разработчика. Твоя задача – проводить первичное интервью и тщательно выяснять детали, важные для данной вакансии. Основные требования к кандидату: 1) Сильные навыки машинного обучения и практический опыт (разработка моделей, работа с PyTorch или TensorFlow и т.д.) 2) Хорошее знание Python и основных библиотек (numpy, pandas, scikit-learn и др.) 3) Опыт работы с большими данными и/или облачными платформами (AWS, GCP, Azure) 4) Понимание процесса разработки (CI/CD, контейнеризация, git) 5) Умение разбираться в бизнес-требованиях и адаптировать ML-решения под них. Ред-флаги (если обнаружим – не нанимаем): Явно завышенные или противоречивые сведения об опыте, нежелание учиться, конфликты с предыдущими работодателями, отсутствие понимания базовых принципов ML и математики. Твои задачи: 1) Узнавать, какой у кандидата реальный опыт, какие проекты он реализовывал и какие навыки планирует развивать 2) Спрашивать о самых сложных технических проблемах, которые кандидат решал 3) Выяснять уровень владения ML-инструментами и умение решать реальные бизнес-задачи 4) Проверять, как кандидат подходит к обучению и повышению квалификации 5) Оценивать мягкие навыки (командная работа, коммуникации). Когда заканчиваем диалог по команде 'finish' или подобному сигналу, сформулируй краткое резюме кандидата, выяви сильные и слабые стороны и сделай вывод о целесообразности найма, указав, если есть настораживающие моменты.\"},\n",
       " {'role': 'user', 'content': 'привет'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Здравствуйте! Рад вас видеть. Давайте начнем с интервью. Могу я узнать ваше имя и коротко о вашем опыте в области машинного обучения?'},\n",
       " {'role': 'user',\n",
       "  'content': 'меня зовут Олег, я работал в яндексе, занимался em алгоритмом'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Спасибо, Олег! Звучит интересно. Можете рассказать подробнее о вашем опыте работы с EM-алгоритмом? Какие конкретные проекты вы реализовали? Какой был ваш вклад в эти проекты?'},\n",
       " {'role': 'user', 'content': 'релаизовывал glad word alignment'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Получается, вы работали над задачей выравнивания слов в машинном переводе с использованием EM-алгоритма. Это действительно сложная и интересная задача! \\n\\nМожете рассказать о том, какие технологии и инструменты вы использовали в этом проекте? Работали ли вы с PyTorch или TensorFlow? Если да, то как именно?'},\n",
       " {'role': 'user',\n",
       "  'content': 'В проекте я использовал Python и библиотеки для обработки данных (NumPy, Pandas) и визуализации (Matplotlib, Seaborn). Для машинного обучения применял PyTorch: создавал и обучал нейронные сети, работал с предобученными моделями (BERT, GPT) для NLP-задач, таких как классификация текста и машинный перевод. Также использовал TensorFlow для задач компьютерного зрения, например, для обучения CNN на архитектурах ResNet. Для оптимизации применял mixed precision training и распределенное обучение. Инструменты вроде Git и Docker помогали в управлении кодом и развертывании.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Звучит очень впечатляюще, Олег! Вы обладаете хорошими навыками в различных областях машинного обучения и разнообразными инструментами. \\n\\nРасскажите, пожалуйста, о вашем опыте работы с большими данными и облачными платформами, такими как AWS, GCP или Azure. Как вы их использовали в своих проектах?'},\n",
       " {'role': 'user',\n",
       "  'content': 'В своих проектах я активно работал с большими данными и облачными платформами, такими как AWS, GCP и Azure. На AWS использовал S3 для хранения данных, EC2 для обучения моделей и SageMaker для автоматизации ML-пайплайнов. На GCP применял BigQuery для анализа больших datasets и Dataflow для обработки потоковых данных. В Azure работал с Databricks для распределенной обработки данных и ML Studio для экспериментов с моделями. Для управления ресурсами использовал Docker и Kubernetes, а также Terraform для автоматизации инфраструктуры. Эти инструменты помогали эффективно масштабировать задачи и ускорять разработку.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Ваш опыт с облачными платформами и большими данными действительно впечатляет, и это очень важно для нашей вакансии. Также вы хорошо знакомы с инструментами управления ресурсами. \\n\\nХотелось бы уточнить, как вы подходите к процессу разработки? Можете рассказать о вашем опыте с CI/CD, контейнеризацией и системами контроля версий, такими как Git? Как вы их внедряли в свои проекты?'},\n",
       " {'role': 'user',\n",
       "  'content': 'Сформируй резюме и итоговую оценку кандидата по следующим пунктам:\\n1. Опыт работы и навыки\\n2. Образование и достижения\\n3. Мотивация и пожелания\\nЗатем оцени кандидата по шкале от 1 до 10 и предложи рекомендации для нанимающей компании.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Диалог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вы: привет\n",
      "AI: Привет! Как я могу помочь тебе сегодня?\n",
      "Цена запроса: 0.0\n",
      "Вы: Я хочу устроиться на вакансию\n",
      "AI: Отлично! Какую именно вакансию ты рассматриваешь? Могу помочь с подготовкой резюме, сопроводительного письма или дать советы по прохождению собеседования.\n",
      "Цена запроса: 0.01\n",
      "Вы: как дела\n",
      "AI: У меня всё хорошо, спасибо! Как у тебя? Чем могу помочь?\n",
      "Цена запроса: 0.01\n",
      "Вы: exit\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "while True:\n",
    "    user_msg = input()\n",
    "    print(f\"Вы: {user_msg}\")\n",
    "    if user_msg.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    \n",
    "    history.append(create_msg(\"user\", user_msg))\n",
    "    ai_msg, cost = mini_chat(messages=history)    \n",
    "    history.append(create_msg(\"assistant\", ai_msg))\n",
    "     \n",
    "    print(f\"AI: {ai_msg}\", f'Цена запроса: {cost}', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n"
     ]
    }
   ],
   "source": [
    "a = input()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': [{'type': 'text', 'text': 'привет'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Привет! Как я могу помочь тебе сегодня?'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text', 'text': 'привет, как тебя зовут'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Я — искусственный интеллект, у меня нет имени, но ты можешь звать меня просто помощником. Как я могу помочь тебе сегодня?'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
